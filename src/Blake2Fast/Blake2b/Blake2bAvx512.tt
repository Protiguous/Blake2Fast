<#@ template language="C#" #>
<#@ output extension=".cs" encoding="utf-8" #>
// Copyright Â© Clinton Ingram and Contributors.  Licensed under the MIT License.

//------------------------------------------------------------------------------
//	<auto-generated>
//		This code was generated from a template.
//		Manual changes will be overwritten if the code is regenerated.
//	</auto-generated>
//------------------------------------------------------------------------------

#if HWINTRINSICS && NET8_0_OR_GREATER
using System.Runtime.Intrinsics;
using System.Runtime.Intrinsics.X86;
using System.Runtime.InteropServices;
using System.Runtime.CompilerServices;

namespace Blake2Fast.Implementation;

#if BLAKE2_PUBLIC
public
#else
internal
#endif
unsafe partial struct Blake2bHashState
{
	// SIMD algorithm described in https://eprint.iacr.org/2012/275.pdf
	[MethodImpl(MethodImplOptions.AggressiveOptimization)]
	private static void mixAvx512(ulong* sh, ulong* m)
	{
		// This nonsense breaks CSE of these reads, tricking JIT into allocating low regsiters to the row vars.
		nuint zero = Sse2.CompareGreaterThan(Vector128<int>.Zero, Vector128<int>.Zero).AsUInt32().ToScalar();
		ulong* piv = (ulong*)Unsafe.AsPointer(ref MemoryMarshal.GetReference(ivle)) + zero;
		var row3 = Avx.LoadVector256(piv);
		var row4 = Avx.LoadVector256(piv + Vector256<ulong>.Count);

		// Again breaking CSE, otherwise JIT wastes good registers caching these reads that aren't used again until the end.
		var row1 = Avx.LoadVector256(sh + zero);
		var row2 = Avx.LoadVector256(sh + zero + Vector256<ulong>.Count);

		row4 = Avx2.Xor(row4, Avx.LoadVector256(sh + Vector256<ulong>.Count * 2)); // t[] and f[]

		var m0 = Avx2.BroadcastVector128ToVector256(m);
		var m1 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count);
		var m2 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 2);
		var m3 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 3);
		var m4 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 4);
		var m5 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 5);
		var m6 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 6);
		var m7 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 7);

<#
for (int i = 0; i < 12; i++) {
	WriteLine($"\t\t//ROUND {i+1}");
	loadcode(i, 0);
	g1();
	loadcode(i, 1);
	g2();
	diagonalize();

	loadcode(i, 2);
	g1();
	loadcode(i, 3);
	g2();
	undiagonalize();
}
#>
		row1 = Avx2.Xor(row1, row3);
		row2 = Avx2.Xor(row2, row4);
		row1 = Avx2.Xor(row1, Avx.LoadVector256(sh));
		row2 = Avx2.Xor(row2, Avx.LoadVector256(sh + Vector256<ulong>.Count));

		Avx.Store(sh, row1);
		Avx.Store(sh + Vector256<ulong>.Count, row2);
	}
}
#endif
<#+

void diagonalize() {
#>
		//DIAGONALIZE
		row1 = Avx2.Permute4x64(row1, 0b_10_01_00_11);
		row4 = Avx2.Permute4x64(row4, 0b_01_00_11_10);
		row3 = Avx2.Permute4x64(row3, 0b_00_11_10_01);

<#+
}

void undiagonalize() {
#>
		//UNDIAGONALIZE
		row1 = Avx2.Permute4x64(row1, 0b_00_11_10_01);
		row4 = Avx2.Permute4x64(row4, 0b_01_00_11_10);
		row3 = Avx2.Permute4x64(row3, 0b_10_01_00_11);

<#+
}

void g1() {
#>

		//G1
		row1 = Avx2.Add(Avx2.Add(row1, b0), row2);
		row4 = Avx512F.VL.RotateRight(Avx2.Xor(row4, row1), 32);

		row3 = Avx2.Add(row3, row4);
		row2 = Avx512F.VL.RotateRight(Avx2.Xor(row2, row3), 24);

<#+
}

void g2() {
#>

		//G2
		row1 = Avx2.Add(Avx2.Add(row1, b0), row2);
		row4 = Avx512F.VL.RotateRight(Avx2.Xor(row4, row1), 16);

		row3 = Avx2.Add(row3, row4);
		row2 = Avx512F.VL.RotateRight(Avx2.Xor(row2, row3), 63);

<#+
}

void loadcode(int round, int part) {
	int r = round % 10 * 10 + part;
	switch (r) {
		case 0:
#>
		<#= round == 0 ? "var " : "" #>t0 = Avx2.UnpackLow(m0, m2);
		<#= round == 0 ? "var " : "" #>t1 = Avx2.UnpackLow(m1, m3);
		<#= round == 0 ? "var " : "" #>b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 1:
#>
		t0 = Avx2.UnpackHigh(m0, m2);
		t1 = Avx2.UnpackHigh(m1, m3);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 2:
#>
		t0 = Avx2.UnpackLow(m7, m5);
		t1 = Avx2.UnpackLow(m4, m6);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 3:
#>
		t0 = Avx2.UnpackHigh(m7, m5);
		t1 = Avx2.UnpackHigh(m4, m6);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 10:
#>
		t0 = Avx2.AlignRight(m7, m4, 8);
		t1 = Avx2.AlignRight(m2, m6, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_00_11).AsUInt64();
<#+
			break;
		case 11:
#>
		t0 = Avx2.AlignRight(m5, m7, 8);
		t1 = Avx2.UnpackLow(m4, m3);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_10_01).AsUInt64();
<#+
			break;
		case 12:
#>
		t0 = Avx2.AlignRight(m0, m2, 8);
		t1 = Avx2.UnpackHigh(m0, m5);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 13:
#>
		t0 = Avx2.AlignRight(m6, m3, 8);
		b0 = Avx.Shuffle(m1.AsDouble(), t0.AsDouble(), 0b_00_11).AsUInt64();
<#+
			break;
		case 20:
#>
		t0 = Avx2.UnpackHigh(m5, m2);
		t1 = Avx2.AlignRight(m6, m7, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 21:
#>
		t0 = Avx2.UnpackLow(m4, m1);
		t1 = Avx2.AlignRight(m0, m6, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 22:
#>
		t0 = Avx2.UnpackHigh(m4, m1);
		t1 = Avx2.AlignRight(m5, m3, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 23:
#>
		t0 = Avx2.UnpackLow(m2, m3);
		t1 = Avx2.AlignRight(m7, m0, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 30:
#>
		t0 = Avx2.UnpackHigh(m3, m6);
		t1 = Avx2.UnpackHigh(m1, m5);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 31:
#>
		t0 = Avx2.AlignRight(m6, m4, 8);
		t1 = Avx2.AlignRight(m7, m0, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 32:
#>
		t0 = Avx2.UnpackHigh(m7, m2);
		t1 = Avx2.UnpackLow(m1, m2);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 33:
#>
		t0 = Avx2.UnpackLow(m4, m5);
		t1 = Avx2.UnpackLow(m3, m0);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 40:
#>
		t0 = Avx2.AlignRight(m1, m4, 8);
		t1 = Avx2.AlignRight(m5, m2, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 41:
#>
		t0 = Avx2.UnpackLow(m0, m2);
		t1 = Avx2.UnpackHigh(m3, m7);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 42:
#>
		t0 = Avx2.UnpackHigh(m1, m5);
		t1 = Avx2.UnpackLow(m7, m3);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 43:
#>
		t0 = Avx2.AlignRight(m4, m0, 8);
		b0 = Avx.Shuffle(m6.AsDouble(), t0.AsDouble(), 0b_10_01).AsUInt64();
<#+
			break;
		case 50:
#>
		t0 = Avx2.UnpackLow(m1, m0);
		t1 = Avx2.UnpackLow(m3, m4);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 51:
#>
		t0 = Avx2.AlignRight(m6, m5, 8);
		t1 = Avx2.AlignRight(m5, m1, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_00_11).AsUInt64();
<#+
			break;
		case 52:
#>
		t0 = Avx2.UnpackHigh(m0, m3);
		t1 = Avx2.AlignRight(m2, m7, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 53:
#>
		t0 = Avx2.UnpackHigh(m4, m2);
		t1 = Avx2.AlignRight(m7, m6, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 60:
#>
		t0 = Avx2.UnpackLow(m6, m7);
		t1 = Avx2.AlignRight(m2, m0, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 61:
#>
		t0 = Avx2.UnpackHigh(m2, m6);
		t1 = Avx2.AlignRight(m5, m7, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 62:
#>
		t0 = Avx2.UnpackLow(m4, m3);
		t1 = Avx2.AlignRight(m0, m4, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 63:
#>
		t0 = Avx2.UnpackHigh(m5, m1);
		t1 = Avx2.AlignRight(m1, m3, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 70:
#>
		t0 = Avx2.UnpackHigh(m3, m1);
		b0 = Avx.Shuffle(m6.AsDouble(), t0.AsDouble(), 0b_10_01).AsUInt64();
<#+
			break;
		case 71:
#>
		t0 = Avx2.UnpackHigh(m5, m0);
		t1 = Avx2.AlignRight(m7, m4, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 72:
#>
		t0 = Avx2.AlignRight(m1, m7, 8);
		t1 = Avx2.AlignRight(m4, m2, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_10_01).AsUInt64();
<#+
			break;
		case 73:
#>
		t0 = Avx2.UnpackLow(m5, m2);
		t1 = Avx2.UnpackLow(m0, m3);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 80:
#>
		t0 = Avx2.AlignRight(m3, m5, 8);
		t1 = Avx2.UnpackLow(m7, m0);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_10_01).AsUInt64();
<#+
			break;
		case 81:
#>
		t0 = Avx2.UnpackHigh(m7, m1);
		b0 = Avx.Shuffle(t0.AsDouble(), m4.AsDouble(), 0b_01_10).AsUInt64();
<#+
			break;
		case 82:
#>
		t0 = Avx2.AlignRight(m5, m6, 8);
		t1 = Avx2.AlignRight(m6, m0, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_00_11).AsUInt64();
<#+
			break;
		case 83:
#>
		t0 = Avx2.UnpackHigh(m2, m3);
		t1 = Avx2.UnpackLow(m1, m2);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 90:
#>
		t0 = Avx2.AlignRight(m5, m3, 8);
		t1 = Avx2.AlignRight(m4, m0, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_00_11).AsUInt64();
<#+
			break;
		case 91:
#>
		t0 = Avx2.UnpackLow(m1, m3);
		b0 = Avx.Shuffle(t0.AsDouble(), m2.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 92:
#>
		t0 = Avx2.UnpackHigh(m6, m4);
		t1 = Avx2.UnpackHigh(m7, m1);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
		case 93:
#>
		t0 = Avx2.UnpackLow(m0, m7);
		t1 = Avx2.AlignRight(m6, m5, 8);
		b0 = Avx.Shuffle(t0.AsDouble(), t1.AsDouble(), 0b_11_00).AsUInt64();
<#+
			break;
	}
}
#>